{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing parquet files...\n",
      "Found 14 parquet files\n",
      "Reading parquet files...\n",
      "Combined DataFrame shape: (10000, 17)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 17 columns):\n",
      " #   Column               Non-Null Count  Dtype              \n",
      "---  ------               --------------  -----              \n",
      " 0   number               10000 non-null  string             \n",
      " 1   event_time           10000 non-null  string             \n",
      " 2   date                 10000 non-null  float64            \n",
      " 3   price                10000 non-null  float64            \n",
      " 4   bedrooms             10000 non-null  float64            \n",
      " 5   bathrooms            10000 non-null  float64            \n",
      " 6   sqft_living          10000 non-null  float64            \n",
      " 7   sqft_lot             10000 non-null  float64            \n",
      " 8   floors               10000 non-null  float64            \n",
      " 9   condition            10000 non-null  float64            \n",
      " 10  grade                10000 non-null  float64            \n",
      " 11  sqft_above           10000 non-null  float64            \n",
      " 12  sqft_basement        10000 non-null  float64            \n",
      " 13  yr_built             10000 non-null  float64            \n",
      " 14  write_time           10000 non-null  datetime64[ns, UTC]\n",
      " 15  api_invocation_time  10000 non-null  datetime64[ns, UTC]\n",
      " 16  is_deleted           10000 non-null  boolean            \n",
      "dtypes: boolean(1), datetime64[ns, UTC](2), float64(12), string(2)\n",
      "memory usage: 1.2 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import awswrangler as wr\n",
    "from typing import List\n",
    "\n",
    "def list_parquet_files(bucket: str, prefix: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    List all parquet files under a given S3 prefix, including date-partitioned folders\n",
    "    \n",
    "    Args:\n",
    "        bucket (str): S3 bucket name\n",
    "        prefix (str): S3 prefix path\n",
    "        \n",
    "    Returns:\n",
    "        List[str]: List of complete S3 URIs for parquet files\n",
    "    \"\"\"\n",
    "    s3_client = boto3.client('s3')\n",
    "    parquet_files = []\n",
    "    \n",
    "    # Remove s3:// if present in bucket name\n",
    "    bucket = bucket.replace('s3://', '')\n",
    "    \n",
    "    # Use delimiter to list folders first\n",
    "    paginator = s3_client.get_paginator('list_objects_v2')\n",
    "    \n",
    "    # First, get all year folders\n",
    "    year_pages = paginator.paginate(Bucket=bucket, Prefix=prefix, Delimiter='/')\n",
    "    \n",
    "    for year_page in year_pages:\n",
    "        if 'CommonPrefixes' in year_page:\n",
    "            for year_prefix in year_page['CommonPrefixes']:\n",
    "                year_path = year_prefix['Prefix']\n",
    "                \n",
    "                # For each year, get month folders\n",
    "                month_pages = paginator.paginate(Bucket=bucket, Prefix=year_path, Delimiter='/')\n",
    "                for month_page in month_pages:\n",
    "                    if 'CommonPrefixes' in month_page:\n",
    "                        for month_prefix in month_page['CommonPrefixes']:\n",
    "                            month_path = month_prefix['Prefix']\n",
    "                            \n",
    "                            # For each month, get day folders\n",
    "                            day_pages = paginator.paginate(Bucket=bucket, Prefix=month_path, Delimiter='/')\n",
    "                            for day_page in day_pages:\n",
    "                                if 'CommonPrefixes' in day_page:\n",
    "                                    for day_prefix in day_page['CommonPrefixes']:\n",
    "                                        day_path = day_prefix['Prefix']\n",
    "                                        \n",
    "                                        # Finally, list parquet files in the day folder\n",
    "                                        file_pages = paginator.paginate(Bucket=bucket, Prefix=day_path)\n",
    "                                        for file_page in file_pages:\n",
    "                                            if 'Contents' in file_page:\n",
    "                                                for obj in file_page['Contents']:\n",
    "                                                    if obj['Key'].endswith('.parquet'):\n",
    "                                                        parquet_files.append(f\"s3://{bucket}/{obj['Key']}\")\n",
    "    \n",
    "    return parquet_files\n",
    "\n",
    "def read_all_parquets(s3_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read and concatenate all parquet files from a given S3 path with date partitions\n",
    "    \n",
    "    Args:\n",
    "        s3_path (str): Base S3 path including bucket and prefix\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Combined DataFrame from all parquet files\n",
    "    \"\"\"\n",
    "    # Split S3 path into bucket and prefix\n",
    "    s3_path = s3_path.rstrip('/')\n",
    "    bucket = s3_path.split('/')[2]\n",
    "    prefix = '/'.join(s3_path.split('/')[3:]) + '/'\n",
    "    \n",
    "    # Get list of all parquet files\n",
    "    print(\"Listing parquet files...\")\n",
    "    parquet_files = list_parquet_files(bucket, prefix)\n",
    "    \n",
    "    if not parquet_files:\n",
    "        raise ValueError(f\"No parquet files found in {s3_path}\")\n",
    "    \n",
    "    # Read all parquet files\n",
    "    print(f\"Found {len(parquet_files)} parquet files\")\n",
    "    print(\"Reading parquet files...\")\n",
    "    df = wr.s3.read_parquet(path=parquet_files)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "try:\n",
    "    s3_path = \"s3://mlo-team4/features/simulation/637423203755/sagemaker/us-east-2/offline-store/housing-feature-group-simulation-1733973023/data/\"\n",
    "    data = read_all_parquets(s3_path)\n",
    "    print(f\"Combined DataFrame shape: {data.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing parquet files...\n",
      "Found 14 parquet files\n",
      "Reading parquet files...\n",
      "Combined DataFrame shape: (3000, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>event_time</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>write_time</th>\n",
       "      <th>api_invocation_time</th>\n",
       "      <th>is_deleted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5189</td>\n",
       "      <td>2024-12-12T02:54:13Z</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>190000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>3101.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1948.0</td>\n",
       "      <td>2024-12-12 03:10:41.978000+00:00</td>\n",
       "      <td>2024-12-12 03:05:51+00:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7843</td>\n",
       "      <td>2024-12-12T02:54:13Z</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>550000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>950.0</td>\n",
       "      <td>4080.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>950.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>2024-12-12 03:10:41.978000+00:00</td>\n",
       "      <td>2024-12-12 03:05:51+00:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>340</td>\n",
       "      <td>2024-12-12T02:54:13Z</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>485000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2560.0</td>\n",
       "      <td>43995.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2560.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>2024-12-12 03:10:41.978000+00:00</td>\n",
       "      <td>2024-12-12 03:05:51+00:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14114</td>\n",
       "      <td>2024-12-12T02:54:13Z</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>275000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>5995.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>2024-12-12 03:10:41.978000+00:00</td>\n",
       "      <td>2024-12-12 03:05:51+00:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15374</td>\n",
       "      <td>2024-12-12T02:54:13Z</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>340000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2650.0</td>\n",
       "      <td>7378.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>1190.0</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>2024-12-12 03:10:41.978000+00:00</td>\n",
       "      <td>2024-12-12 03:05:51+00:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>15463</td>\n",
       "      <td>2024-12-12T02:54:13Z</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>235000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>8400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>2024-12-12 03:10:42.385000+00:00</td>\n",
       "      <td>2024-12-12 03:06:04+00:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>10123</td>\n",
       "      <td>2024-12-12T02:54:13Z</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>465000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>4808.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2024-12-12 03:10:42.385000+00:00</td>\n",
       "      <td>2024-12-12 03:06:04+00:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>7979</td>\n",
       "      <td>2024-12-12T02:54:13Z</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>590000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2940.0</td>\n",
       "      <td>12600.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1850.0</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>2024-12-12 03:10:42.385000+00:00</td>\n",
       "      <td>2024-12-12 03:06:04+00:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>2475</td>\n",
       "      <td>2024-12-12T02:54:13Z</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>345000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>970.0</td>\n",
       "      <td>10423.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>970.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1947.0</td>\n",
       "      <td>2024-12-12 03:10:42.385000+00:00</td>\n",
       "      <td>2024-12-12 03:06:04+00:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>21595</td>\n",
       "      <td>2024-12-12T02:54:13Z</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>520000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1530.0</td>\n",
       "      <td>981.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>2024-12-12 03:10:42.385000+00:00</td>\n",
       "      <td>2024-12-12 03:06:04+00:00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     number            event_time    date     price  bedrooms  bathrooms  \\\n",
       "0      5189  2024-12-12T02:54:13Z  2015.0  190000.0       2.0        1.0   \n",
       "1      7843  2024-12-12T02:54:13Z  2014.0  550000.0       2.0        1.0   \n",
       "2       340  2024-12-12T02:54:13Z  2015.0  485000.0       4.0        1.0   \n",
       "3     14114  2024-12-12T02:54:13Z  2015.0  275000.0       2.0        2.0   \n",
       "4     15374  2024-12-12T02:54:13Z  2015.0  340000.0       3.0        1.0   \n",
       "...     ...                   ...     ...       ...       ...        ...   \n",
       "2995  15463  2024-12-12T02:54:13Z  2015.0  235000.0       3.0        2.0   \n",
       "2996  10123  2024-12-12T02:54:13Z  2015.0  465000.0       3.0        2.0   \n",
       "2997   7979  2024-12-12T02:54:13Z  2015.0  590000.0       4.0        2.0   \n",
       "2998   2475  2024-12-12T02:54:13Z  2014.0  345000.0       2.0        1.0   \n",
       "2999  21595  2024-12-12T02:54:13Z  2014.0  520000.0       2.0        2.0   \n",
       "\n",
       "      sqft_living  sqft_lot  floors  condition  grade  sqft_above  \\\n",
       "0           670.0    3101.0     1.0        4.0    6.0       670.0   \n",
       "1           950.0    4080.0     1.0        4.0    7.0       950.0   \n",
       "2          2560.0   43995.0     2.0        4.0    7.0      2560.0   \n",
       "3          1340.0    5995.0     2.0        3.0    7.0      1340.0   \n",
       "4          2650.0    7378.0     1.0        3.0    7.0      1460.0   \n",
       "...           ...       ...     ...        ...    ...         ...   \n",
       "2995       1090.0    8400.0     1.0        4.0    6.0      1090.0   \n",
       "2996       1890.0    4808.0     2.0        3.0    8.0      1890.0   \n",
       "2997       2940.0   12600.0     1.0        4.0    8.0      1850.0   \n",
       "2998        970.0   10423.0     1.0        3.0    7.0       970.0   \n",
       "2999       1530.0     981.0     3.0        3.0    8.0      1480.0   \n",
       "\n",
       "      sqft_basement  yr_built                       write_time  \\\n",
       "0               0.0    1948.0 2024-12-12 03:10:41.978000+00:00   \n",
       "1               0.0    1924.0 2024-12-12 03:10:41.978000+00:00   \n",
       "2               0.0    1962.0 2024-12-12 03:10:41.978000+00:00   \n",
       "3               0.0    1989.0 2024-12-12 03:10:41.978000+00:00   \n",
       "4            1190.0    1952.0 2024-12-12 03:10:41.978000+00:00   \n",
       "...             ...       ...                              ...   \n",
       "2995            0.0    1961.0 2024-12-12 03:10:42.385000+00:00   \n",
       "2996            0.0    2000.0 2024-12-12 03:10:42.385000+00:00   \n",
       "2997         1090.0    1974.0 2024-12-12 03:10:42.385000+00:00   \n",
       "2998            0.0    1947.0 2024-12-12 03:10:42.385000+00:00   \n",
       "2999           50.0    2006.0 2024-12-12 03:10:42.385000+00:00   \n",
       "\n",
       "           api_invocation_time  is_deleted  \n",
       "0    2024-12-12 03:05:51+00:00       False  \n",
       "1    2024-12-12 03:05:51+00:00       False  \n",
       "2    2024-12-12 03:05:51+00:00       False  \n",
       "3    2024-12-12 03:05:51+00:00       False  \n",
       "4    2024-12-12 03:05:51+00:00       False  \n",
       "...                        ...         ...  \n",
       "2995 2024-12-12 03:06:04+00:00       False  \n",
       "2996 2024-12-12 03:06:04+00:00       False  \n",
       "2997 2024-12-12 03:06:04+00:00       False  \n",
       "2998 2024-12-12 03:06:04+00:00       False  \n",
       "2999 2024-12-12 03:06:04+00:00       False  \n",
       "\n",
       "[3000 rows x 17 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def list_parquet_files(bucket: str, prefix: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    List all parquet files under a given S3 prefix, including date-partitioned folders\n",
    "    \n",
    "    Args:\n",
    "        bucket (str): S3 bucket name\n",
    "        prefix (str): S3 prefix path\n",
    "        \n",
    "    Returns:\n",
    "        List[str]: List of complete S3 URIs for parquet files\n",
    "    \"\"\"\n",
    "    s3_client = boto3.client('s3')\n",
    "    parquet_files = []\n",
    "    \n",
    "    # Remove s3:// if present in bucket name\n",
    "    bucket = bucket.replace('s3://', '')\n",
    "    \n",
    "    # Use delimiter to list folders first\n",
    "    paginator = s3_client.get_paginator('list_objects_v2')\n",
    "    \n",
    "    # First, get all year folders\n",
    "    year_pages = paginator.paginate(Bucket=bucket, Prefix=prefix, Delimiter='/')\n",
    "    \n",
    "    for year_page in year_pages:\n",
    "        if 'CommonPrefixes' in year_page:\n",
    "            for year_prefix in year_page['CommonPrefixes']:\n",
    "                year_path = year_prefix['Prefix']\n",
    "                \n",
    "                # For each year, get month folders\n",
    "                month_pages = paginator.paginate(Bucket=bucket, Prefix=year_path, Delimiter='/')\n",
    "                for month_page in month_pages:\n",
    "                    if 'CommonPrefixes' in month_page:\n",
    "                        for month_prefix in month_page['CommonPrefixes']:\n",
    "                            month_path = month_prefix['Prefix']\n",
    "                            \n",
    "                            # For each month, get day folders\n",
    "                            day_pages = paginator.paginate(Bucket=bucket, Prefix=month_path, Delimiter='/')\n",
    "                            for day_page in day_pages:\n",
    "                                if 'CommonPrefixes' in day_page:\n",
    "                                    for day_prefix in day_page['CommonPrefixes']:\n",
    "                                        day_path = day_prefix['Prefix']\n",
    "                                        \n",
    "                                        # Finally, list parquet files in the day folder\n",
    "                                        file_pages = paginator.paginate(Bucket=bucket, Prefix=day_path)\n",
    "                                        for file_page in file_pages:\n",
    "                                            if 'Contents' in file_page:\n",
    "                                                for obj in file_page['Contents']:\n",
    "                                                    if obj['Key'].endswith('.parquet'):\n",
    "                                                        parquet_files.append(f\"s3://{bucket}/{obj['Key']}\")\n",
    "    \n",
    "    return parquet_files\n",
    "\n",
    "def read_all_parquets(s3_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read and concatenate all parquet files from a given S3 path with date partitions\n",
    "    \n",
    "    Args:\n",
    "        s3_path (str): Base S3 path including bucket and prefix\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Combined DataFrame from all parquet files\n",
    "    \"\"\"\n",
    "    # Split S3 path into bucket and prefix\n",
    "    s3_path = s3_path.rstrip('/')\n",
    "    bucket = s3_path.split('/')[2]\n",
    "    prefix = '/'.join(s3_path.split('/')[3:]) + '/'\n",
    "    \n",
    "    # Get list of all parquet files\n",
    "    print(\"Listing parquet files...\")\n",
    "    parquet_files = list_parquet_files(bucket, prefix)\n",
    "    \n",
    "    if not parquet_files:\n",
    "        raise ValueError(f\"No parquet files found in {s3_path}\")\n",
    "    \n",
    "    # Read all parquet files\n",
    "    print(f\"Found {len(parquet_files)} parquet files\")\n",
    "    print(\"Reading parquet files...\")\n",
    "    df = wr.s3.read_parquet(path=parquet_files)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "try:\n",
    "    s3_path = \"s3://mlo-team4/features/test/637423203755/sagemaker/us-east-2/offline-store/housing-feature-group-test-1733972554/data/\"\n",
    "    test_data = read_all_parquets(s3_path)\n",
    "    print(f\"Combined DataFrame shape: {test_data.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Training Data': 8000, 'Validation Data': 2000, 'Test Data': 3000}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, validation_data= train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "splits_summary = {\n",
    "    \"Training Data\": train_data.shape[0],\n",
    "    \"Validation Data\": validation_data.shape[0],\n",
    "    \"Test Data\": test_data.shape[0],\n",
    "}\n",
    "\n",
    "print(splits_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "columns_to_drop = ['Unnamed: 0',\n",
    " 'number',\n",
    " 'event_time',\n",
    " 'write_time',\n",
    " 'api_invocation_time',\n",
    "    'is_deleted']  \n",
    "train_data = train_data.drop(columns=columns_to_drop, errors='ignore')\n",
    "validation_data = validation_data.drop(columns=columns_to_drop, errors='ignore')\n",
    "test_data = test_data.drop(columns=columns_to_drop, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install h2o\n",
    "#!pip install xgboost\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-4.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-4 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-4 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-4 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table th,\n",
       "#h2o-table-4 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-4 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-4\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>1 hour 10 mins</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.6</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 month and 10 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_ec2_user_7vek2j</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>7.664 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.10.14 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -------------------------------\n",
       "H2O_cluster_uptime:         1 hour 10 mins\n",
       "H2O_cluster_timezone:       UTC\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.6\n",
       "H2O_cluster_version_age:    1 month and 10 days\n",
       "H2O_cluster_name:           H2O_from_python_ec2_user_7vek2j\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    7.664 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.10.14 final\n",
       "--------------------------  -------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "05:05:02.103: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n",
      "\n",
      "███████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2OStackedEnsembleEstimator : Stacked Ensemble\n",
       "Model Key: StackedEnsemble_AllModels_1_AutoML_2_20241212_50502\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-5.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-5 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-5 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-5 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table th,\n",
       "#h2o-table-5 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-5 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-5\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Model Summary for Stacked Ensemble: </caption>\n",
       "    <thead><tr><th>key</th>\n",
       "<th>value</th></tr></thead>\n",
       "    <tbody><tr><td>Stacking strategy</td>\n",
       "<td>cross_validation</td></tr>\n",
       "<tr><td>Number of base models (used / total)</td>\n",
       "<td>10/20</td></tr>\n",
       "<tr><td># GBM base models (used / total)</td>\n",
       "<td>4/7</td></tr>\n",
       "<tr><td># XGBoost base models (used / total)</td>\n",
       "<td>3/6</td></tr>\n",
       "<tr><td># DeepLearning base models (used / total)</td>\n",
       "<td>3/4</td></tr>\n",
       "<tr><td># DRF base models (used / total)</td>\n",
       "<td>0/2</td></tr>\n",
       "<tr><td># GLM base models (used / total)</td>\n",
       "<td>0/1</td></tr>\n",
       "<tr><td>Metalearner algorithm</td>\n",
       "<td>GLM</td></tr>\n",
       "<tr><td>Metalearner fold assignment scheme</td>\n",
       "<td>Random</td></tr>\n",
       "<tr><td>Metalearner nfolds</td>\n",
       "<td>5</td></tr>\n",
       "<tr><td>Metalearner fold_column</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>Custom metalearner hyperparameters</td>\n",
       "<td>None</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsRegressionGLM: stackedensemble\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 29065182354.743614\n",
       "RMSE: 170485.13822249614\n",
       "MAE: 112556.08822965472\n",
       "RMSLE: 0.27458327406120414\n",
       "Mean Residual Deviance: 29065182354.743614\n",
       "R^2: 0.804553879067563\n",
       "Null degrees of freedom: 7999\n",
       "Residual degrees of freedom: 7989\n",
       "Null deviance: 1189695951644695.2\n",
       "Residual deviance: 232521458837948.9\n",
       "AIC: 215469.4710281721</pre></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsRegressionGLM: stackedensemble\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 38335159662.395294\n",
       "RMSE: 195793.66604258498\n",
       "MAE: 126289.45381902094\n",
       "RMSLE: 0.3041402557600965\n",
       "Mean Residual Deviance: 38335159662.395294\n",
       "R^2: 0.7314041219223855\n",
       "Null degrees of freedom: 1999\n",
       "Residual degrees of freedom: 1989\n",
       "Null deviance: 285466404572349.7\n",
       "Residual deviance: 76670319324790.6\n",
       "AIC: 54439.02077056564</pre></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsRegressionGLM: stackedensemble\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 44062242155.74775\n",
       "RMSE: 209910.08111986367\n",
       "MAE: 132270.0991155818\n",
       "RMSLE: 0.31230003472978846\n",
       "Mean Residual Deviance: 44062242155.74775\n",
       "R^2: 0.703707542453416\n",
       "Null degrees of freedom: 7999\n",
       "Residual degrees of freedom: 7989\n",
       "Null deviance: 1190160672537751.5\n",
       "Residual deviance: 352497937245982.0\n",
       "AIC: 218797.9690570134</pre></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-6.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-6 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-6 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-6 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table th,\n",
       "#h2o-table-6 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-6 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-6\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Cross-Validation Metrics Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>mean</th>\n",
       "<th>sd</th>\n",
       "<th>cv_1_valid</th>\n",
       "<th>cv_2_valid</th>\n",
       "<th>cv_3_valid</th>\n",
       "<th>cv_4_valid</th>\n",
       "<th>cv_5_valid</th></tr></thead>\n",
       "    <tbody><tr><td>aic</td>\n",
       "<td>43775.387</td>\n",
       "<td>1837.6389</td>\n",
       "<td>45198.465</td>\n",
       "<td>44678.137</td>\n",
       "<td>44199.02</td>\n",
       "<td>44232.086</td>\n",
       "<td>40569.22</td></tr>\n",
       "<tr><td>loglikelihood</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mae</td>\n",
       "<td>132143.75</td>\n",
       "<td>1874.5265</td>\n",
       "<td>133982.98</td>\n",
       "<td>132818.19</td>\n",
       "<td>130859.6640000</td>\n",
       "<td>133505.45</td>\n",
       "<td>129552.4840000</td></tr>\n",
       "<tr><td>mean_residual_deviance</td>\n",
       "<td>43976827000.0000000</td>\n",
       "<td>2896264190.0000000</td>\n",
       "<td>44734210000.0000000</td>\n",
       "<td>47090815000.0000000</td>\n",
       "<td>40018055000.0000000</td>\n",
       "<td>45970805000.0000000</td>\n",
       "<td>42070249000.0000000</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>43976827000.0000000</td>\n",
       "<td>2896264190.0000000</td>\n",
       "<td>44734210000.0000000</td>\n",
       "<td>47090815000.0000000</td>\n",
       "<td>40018055000.0000000</td>\n",
       "<td>45970805000.0000000</td>\n",
       "<td>42070249000.0000000</td></tr>\n",
       "<tr><td>null_deviance</td>\n",
       "<td>238032137000000.0000000</td>\n",
       "<td>32143312900000.0000000</td>\n",
       "<td>232529378000000.0000000</td>\n",
       "<td>281071401000000.0000000</td>\n",
       "<td>221897288000000.0000000</td>\n",
       "<td>257002521000000.0000000</td>\n",
       "<td>197660099000000.0000000</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.7021232</td>\n",
       "<td>0.0191558</td>\n",
       "<td>0.6823707</td>\n",
       "<td>0.7268159</td>\n",
       "<td>0.707394</td>\n",
       "<td>0.7109457</td>\n",
       "<td>0.6830898</td></tr>\n",
       "<tr><td>residual_deviance</td>\n",
       "<td>70421517000000.0000000</td>\n",
       "<td>6316494400000.0000000</td>\n",
       "<td>73856182000000.0000000</td>\n",
       "<td>76710934000000.0000000</td>\n",
       "<td>64869269000000.0000000</td>\n",
       "<td>74196877000000.0000000</td>\n",
       "<td>62474322000000.0000000</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>209614.47</td>\n",
       "<td>6946.548</td>\n",
       "<td>211504.64</td>\n",
       "<td>217004.19</td>\n",
       "<td>200045.14</td>\n",
       "<td>214408.03</td>\n",
       "<td>205110.34</td></tr>\n",
       "<tr><td>rmsle</td>\n",
       "<td>0.3123729</td>\n",
       "<td>0.0044544</td>\n",
       "<td>0.3141195</td>\n",
       "<td>0.3100301</td>\n",
       "<td>0.3147326</td>\n",
       "<td>0.3058474</td>\n",
       "<td>0.3171351</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2OStackedEnsembleEstimator : Stacked Ensemble\n",
       "Model Key: StackedEnsemble_AllModels_1_AutoML_2_20241212_50502\n",
       "\n",
       "\n",
       "Model Summary for Stacked Ensemble: \n",
       "key                                        value\n",
       "-----------------------------------------  ----------------\n",
       "Stacking strategy                          cross_validation\n",
       "Number of base models (used / total)       10/20\n",
       "# GBM base models (used / total)           4/7\n",
       "# XGBoost base models (used / total)       3/6\n",
       "# DeepLearning base models (used / total)  3/4\n",
       "# DRF base models (used / total)           0/2\n",
       "# GLM base models (used / total)           0/1\n",
       "Metalearner algorithm                      GLM\n",
       "Metalearner fold assignment scheme         Random\n",
       "Metalearner nfolds                         5\n",
       "Metalearner fold_column\n",
       "Custom metalearner hyperparameters         None\n",
       "\n",
       "ModelMetricsRegressionGLM: stackedensemble\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 29065182354.743614\n",
       "RMSE: 170485.13822249614\n",
       "MAE: 112556.08822965472\n",
       "RMSLE: 0.27458327406120414\n",
       "Mean Residual Deviance: 29065182354.743614\n",
       "R^2: 0.804553879067563\n",
       "Null degrees of freedom: 7999\n",
       "Residual degrees of freedom: 7989\n",
       "Null deviance: 1189695951644695.2\n",
       "Residual deviance: 232521458837948.9\n",
       "AIC: 215469.4710281721\n",
       "\n",
       "ModelMetricsRegressionGLM: stackedensemble\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 38335159662.395294\n",
       "RMSE: 195793.66604258498\n",
       "MAE: 126289.45381902094\n",
       "RMSLE: 0.3041402557600965\n",
       "Mean Residual Deviance: 38335159662.395294\n",
       "R^2: 0.7314041219223855\n",
       "Null degrees of freedom: 1999\n",
       "Residual degrees of freedom: 1989\n",
       "Null deviance: 285466404572349.7\n",
       "Residual deviance: 76670319324790.6\n",
       "AIC: 54439.02077056564\n",
       "\n",
       "ModelMetricsRegressionGLM: stackedensemble\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 44062242155.74775\n",
       "RMSE: 209910.08111986367\n",
       "MAE: 132270.0991155818\n",
       "RMSLE: 0.31230003472978846\n",
       "Mean Residual Deviance: 44062242155.74775\n",
       "R^2: 0.703707542453416\n",
       "Null degrees of freedom: 7999\n",
       "Residual degrees of freedom: 7989\n",
       "Null deviance: 1190160672537751.5\n",
       "Residual deviance: 352497937245982.0\n",
       "AIC: 218797.9690570134\n",
       "\n",
       "Cross-Validation Metrics Summary: \n",
       "                        mean         sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "----------------------  -----------  -----------  ------------  ------------  ------------  ------------  ------------\n",
       "aic                     43775.4      1837.64      45198.5       44678.1       44199         44232.1       40569.2\n",
       "loglikelihood           0            0            0             0             0             0             0\n",
       "mae                     132144       1874.53      133983        132818        130860        133505        129552\n",
       "mean_residual_deviance  4.39768e+10  2.89626e+09  4.47342e+10   4.70908e+10   4.00181e+10   4.59708e+10   4.20702e+10\n",
       "mse                     4.39768e+10  2.89626e+09  4.47342e+10   4.70908e+10   4.00181e+10   4.59708e+10   4.20702e+10\n",
       "null_deviance           2.38032e+14  3.21433e+13  2.32529e+14   2.81071e+14   2.21897e+14   2.57003e+14   1.9766e+14\n",
       "r2                      0.702123     0.0191558    0.682371      0.726816      0.707394      0.710946      0.68309\n",
       "residual_deviance       7.04215e+13  6.31649e+12  7.38562e+13   7.67109e+13   6.48693e+13   7.41969e+13   6.24743e+13\n",
       "rmse                    209614       6946.55      211505        217004        200045        214408        205110\n",
       "rmsle                   0.312373     0.00445444   0.314119      0.31003       0.314733      0.305847      0.317135\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "h2o.init()\n",
    "\n",
    "train_h2o = h2o.H2OFrame(train_data)\n",
    "validation_h2o = h2o.H2OFrame(validation_data)\n",
    "test_h2o = h2o.H2OFrame(test_data)\n",
    "\n",
    "target = 'price'\n",
    "features = [col for col in train_data.columns if col != target]\n",
    "\n",
    "\n",
    "\n",
    "aml = H2OAutoML(max_models=20, seed=42, exclude_algos=None)\n",
    "aml.train(x=features, y=target, training_frame=train_h2o, validation_frame=validation_h2o)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id                                                  rmse          mse     mae       rmsle    mean_residual_deviance\n",
      "StackedEnsemble_AllModels_1_AutoML_2_20241212_50502     209910  4.40622e+10  132270    0.3123                 4.40622e+10\n",
      "StackedEnsemble_BestOfFamily_1_AutoML_2_20241212_50502  210767  4.44226e+10  132733    0.314223               4.44226e+10\n",
      "DeepLearning_grid_2_AutoML_2_20241212_50502_model_1     215650  4.65051e+10  138419    0.327862               4.65051e+10\n",
      "GBM_2_AutoML_2_20241212_50502                           216362  4.68127e+10  133623    0.316034               4.68127e+10\n",
      "DeepLearning_grid_3_AutoML_2_20241212_50502_model_1     216530  4.68853e+10  137927    0.324232               4.68853e+10\n",
      "GBM_3_AutoML_2_20241212_50502                           216969  4.70754e+10  133527    0.316078               4.70754e+10\n",
      "GBM_4_AutoML_2_20241212_50502                           217150  4.7154e+10   133895    0.316387               4.7154e+10\n",
      "GBM_grid_1_AutoML_2_20241212_50502_model_2              219141  4.80227e+10  134531    0.316951               4.80227e+10\n",
      "DeepLearning_grid_1_AutoML_2_20241212_50502_model_1     219337  4.81086e+10  140140  nan                      4.81086e+10\n",
      "DRF_1_AutoML_2_20241212_50502                           220347  4.85527e+10  135366    0.319627               4.85527e+10\n",
      "[22 rows x 6 columns]\n",
      "\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "         predict\n",
      "0  288383.790781\n",
      "1  440583.256201\n",
      "2  526815.216853\n",
      "3  312029.324241\n",
      "4  542189.606537\n"
     ]
    }
   ],
   "source": [
    "leaderboard = aml.leaderboard\n",
    "print(leaderboard)\n",
    "\n",
    "predictions = aml.leader.predict(test_h2o)\n",
    "\n",
    "pred_df = predictions.as_data_frame()\n",
    "print(pred_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StackedEnsemble_AllModels_1_AutoML_2_20241212_...</td>\n",
       "      <td>209910.08112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            model_id          rmse\n",
       "0  StackedEnsemble_AllModels_1_AutoML_2_20241212_...  209910.08112"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard_df = leaderboard.as_data_frame()\n",
    "\n",
    "best_model_row = leaderboard_df.loc[leaderboard_df['rmse'].idxmin()]\n",
    "best_model_id = best_model_row['model_id']\n",
    "best_rmse = best_model_row['rmse']\n",
    "\n",
    "best_model_df = pd.DataFrame({\n",
    "    'model_id': [best_model_id],\n",
    "    'rmse': [best_rmse]\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install evidently\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import os\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset, DataQualityPreset, TargetDriftPreset, RegressionPreset\n",
    "\n",
    "def prepare_monitoring_data(train_data, test_data, predictions, target_column='price'):\n",
    "    \"\"\"\n",
    "    Prepare data for Evidently monitoring\n",
    "    \"\"\"\n",
    "    reference_data = train_data.copy()\n",
    "    current_data = test_data.copy()\n",
    "    \n",
    "    # Get model predictions\n",
    "    reference_predictions = aml.leader.predict(h2o.H2OFrame(reference_data))\n",
    "    reference_predictions = reference_predictions.as_data_frame()\n",
    "    reference_data['prediction'] = reference_predictions['predict'].values\n",
    "    current_data['prediction'] = predictions\n",
    "    \n",
    "    # Rename target column for Evidently\n",
    "    reference_data = reference_data.rename(columns={target_column: 'target'})\n",
    "    current_data = current_data.rename(columns={target_column: 'target'})\n",
    "    \n",
    "    # Drop any unnecessary columns \n",
    "    columns_to_keep = list(reference_data.columns)\n",
    "    reference_data = reference_data[columns_to_keep]\n",
    "    current_data = current_data[columns_to_keep]\n",
    "    \n",
    "    return reference_data, current_data\n",
    "\n",
    "def create_monitoring_report(reference_data, current_data, s3_bucket='mlo4-res', s3_prefix='evidently'):\n",
    "    \"\"\"\n",
    "    Generate comprehensive monitoring report using Evidently and save to S3\n",
    "    \"\"\"\n",
    "    # Initialize S3 client\n",
    "    s3 = boto3.client('s3')\n",
    "    \n",
    "    # Create report\n",
    "    report = Report(metrics=[\n",
    "        DataQualityPreset(),\n",
    "        DataDriftPreset(),\n",
    "        TargetDriftPreset(),\n",
    "        RegressionPreset()\n",
    "    ])\n",
    "    \n",
    "    # Run report\n",
    "    try:\n",
    "        report.run(reference_data=reference_data, current_data=current_data)\n",
    "    except Exception as e:\n",
    "        print(\"Debug info:\")\n",
    "        print(f\"Reference data columns: {reference_data.columns.tolist()}\")\n",
    "        print(f\"Current data columns: {current_data.columns.tolist()}\")\n",
    "        print(f\"Reference data shape: {reference_data.shape}\")\n",
    "        print(f\"Current data shape: {current_data.shape}\")\n",
    "        raise e\n",
    "    \n",
    "    # Save report locally first\n",
    "    timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')\n",
    "    report_path = f'monitoring_report_{timestamp}.html'\n",
    "    \n",
    "    report.save_html(report_path)\n",
    "    \n",
    "    # Upload to S3\n",
    "    s3.upload_file(\n",
    "        report_path, \n",
    "        s3_bucket, \n",
    "        f'{s3_prefix}/monitoring_report_{timestamp}.html'\n",
    "    )\n",
    "    \n",
    "    # Clean up local file\n",
    "    os.remove(report_path)\n",
    "    \n",
    "    print(f\"Report saved to s3://{s3_bucket}/{s3_prefix}/monitoring_report_{timestamp}.html\")\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "Before creating report:\n",
      "Reference data columns: ['date', 'target', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'prediction']\n",
      "Current data columns: ['date', 'target', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'prediction']\n",
      "Report saved to s3://mlo4-res/evidently/monitoring_report_20241212_050955.html\n"
     ]
    }
   ],
   "source": [
    "# After your predictions\n",
    "reference_data, current_data = prepare_monitoring_data(\n",
    "    train_data=train_h2o.as_data_frame(),\n",
    "    test_data=test_h2o.as_data_frame(), \n",
    "    predictions=pred_df['predict'].values,\n",
    "    target_column='price'\n",
    ")\n",
    "\n",
    "# Print debug info before creating report\n",
    "print(\"Before creating report:\")\n",
    "print(f\"Reference data columns: {reference_data.columns.tolist()}\")\n",
    "print(f\"Current data columns: {current_data.columns.tolist()}\")\n",
    "\n",
    "report = create_monitoring_report(\n",
    "    reference_data=reference_data,\n",
    "    current_data=current_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current model RMSE: 209910.08111986367\n",
      "Existing best model RMSE: 209910.08111986367\n",
      "Current model is not better than the existing best model.\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.client('s3')\n",
    "bucket_name = 'mlo4-res'\n",
    "s3_key = 'housing_automl/best_model_info.csv'\n",
    "\n",
    "try:\n",
    "    s3.download_file(bucket_name, s3_key, 'existing_best_model_info.csv')\n",
    "    existing_best_model_df = pd.read_csv('existing_best_model_info.csv')\n",
    "    \n",
    "    if existing_best_model_df.empty:\n",
    "        existing_best_model_df = pd.DataFrame({'model_id': [''], 'rmse': [float('inf')], 'training_time_ms': [float('inf')]})\n",
    "except:\n",
    "    existing_best_model_df = pd.DataFrame({'model_id': [''], 'rmse': [float('inf')], 'training_time_ms': [float('inf')]})\n",
    "\n",
    "leaderboard_df = leaderboard.as_data_frame()\n",
    "\n",
    "current_best_model_row = leaderboard_df.loc[leaderboard_df['rmse'].idxmin()]\n",
    "current_best_model_id = current_best_model_row['model_id']\n",
    "current_best_rmse = current_best_model_row['rmse']\n",
    "\n",
    "# Get training time for the current best model\n",
    "current_best_model = h2o.get_model(current_best_model_id)\n",
    "current_best_training_time = current_best_model._model_json['output']['run_time']\n",
    "\n",
    "print(f\"Current model RMSE: {current_best_rmse}\")\n",
    "print(f\"Existing best model RMSE: {existing_best_model_df['rmse'].iloc[0]}\")\n",
    "\n",
    "if current_best_rmse < existing_best_model_df['rmse'].iloc[0] or existing_best_model_df['rmse'].iloc[0] == 0:\n",
    "\n",
    "    new_best_model_df = pd.DataFrame({\n",
    "        'model_id': [current_best_model_id],\n",
    "        'rmse': [current_best_rmse],\n",
    "        'training_time_ms': [current_best_training_time]\n",
    "    })\n",
    "    \n",
    "    new_best_model_df.to_csv('best_model_info.csv', index=False)\n",
    "    \n",
    "    s3.upload_file('best_model_info.csv', bucket_name, s3_key)\n",
    "    \n",
    "    best_model = aml.leader\n",
    "    model_path = h2o.save_model(model=best_model, path=\"h2o_models/\", force=True)\n",
    "    print(f\"Model saved to: {model_path}\")\n",
    "    \n",
    "    s3_model_key = \"housing_automl/h2o_best_model.zip\"\n",
    "    s3.upload_file(Filename=model_path, Bucket=bucket_name, Key=s3_model_key)\n",
    "    print(f\"Model uploaded to s3://{bucket_name}/{s3_model_key}\")\n",
    "else:\n",
    "    print(\"Current model is not better than the existing best model.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
